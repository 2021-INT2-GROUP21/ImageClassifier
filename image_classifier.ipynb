{
 "cells": [
  {
   "source": [
    "<h1>Image Classifier</h1>\n",
    "Module Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split"
   ],
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "source": [
    "<h2>Cuda Test</h2>\n",
    "Code line used to check that cuda is running on the system"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.8394,  0.9832,  0.6699, -1.8981, -1.1155], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "torch.randn(5).cuda()"
   ]
  },
  {
   "source": [
    "<h2>Neural Network Model Class</h2>\n",
    "The class that defines the neural network.\n",
    "Methods include the convolution layer made up of three blocks, each representing a layer in the network and params representing the number of nodes.\n",
    "Conv_layer is used to filter the data and learn from it.\n",
    "FC_layer is the feature configuration layer taking the filtered data to apply and recognise features.\n",
    "Forward is the method to move a data, x, through the network to reach an output from input."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flexible model\n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(p=0.05),\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten images into vectors\n",
    "         # conv layers\n",
    "        x = self.conv_layer(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CIFAR10Model().cuda()"
   ]
  },
  {
   "source": [
    "<h2>Optimiser and Loss Functions</h2>\n",
    "Using the inbuilt functionality from pytorch to create the loss and optimiser functions to train the neural network."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimiser\n",
    "params = model.parameters()\n",
    "optimiser = optim.SGD(params, lr=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "source": [
    "<h2>Load training and validation data</h2>\n",
    "The CIFAR10 dataset is loaded here and transformed into tensors, whereby the 32x32 pixel images are transformed into multidimensional arrays and normalised so that it may be passed as input data to train the neural network. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, val, label\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_data = datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
    "\n",
    "val_size = 5000\n",
    "batch_size = 64\n",
    "train, val = random_split(train_data, [len(train_data)-val_size, val_size])\n",
    "train_loader = DataLoader(train, batch_size=batch_size)\n",
    "val_loader = DataLoader(val, batch_size=batch_size)"
   ]
  },
  {
   "source": [
    "<h2>Training</h2>\n",
    "This is where the model is trained. Epoch is the number of iterations the model trains for and outputs the loss value, how far the model was from the correct class, and accuracy of how many correct guesses it classified the images.\n",
    "Training is split into two where the train_loader is used to adjust the network via gradient descent implemented by pyTorch, val_loader is used to test the model to ensure it is not overfitting to the training data where it runs the model without changing the network."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, train loss: 1.75, train acc: 0.35\n",
      "Epoch 1, val loss: 1.50, val acc: 0.44\n",
      "Epoch 2, train loss: 1.24, train acc: 0.54\n",
      "Epoch 2, val loss: 1.22, val acc: 0.55\n",
      "Epoch 3, train loss: 0.99, train acc: 0.64\n",
      "Epoch 3, val loss: 1.27, val acc: 0.56\n",
      "Epoch 4, train loss: 0.82, train acc: 0.71\n",
      "Epoch 4, val loss: 1.08, val acc: 0.62\n",
      "Epoch 5, train loss: 0.70, train acc: 0.75\n",
      "Epoch 5, val loss: 0.89, val acc: 0.69\n",
      "Epoch 6, train loss: 0.61, train acc: 0.78\n",
      "Epoch 6, val loss: 0.76, val acc: 0.74\n",
      "Epoch 7, train loss: 0.54, train acc: 0.81\n",
      "Epoch 7, val loss: 0.79, val acc: 0.73\n",
      "Epoch 8, train loss: 0.47, train acc: 0.84\n",
      "Epoch 8, val loss: 0.69, val acc: 0.77\n"
     ]
    }
   ],
   "source": [
    "#training and validation loop\n",
    "\n",
    "num_epochs = 8\n",
    "for epoch in range(num_epochs):\n",
    "    losses = list()\n",
    "    accuracies = list()\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        l = model(x)\n",
    "        J = loss(l, y)\n",
    "        model.zero_grad()\n",
    "        J.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        losses.append(J.item())\n",
    "        accuracies.append(y.eq(l.detach().argmax(dim=1)).float().mean())\n",
    "    print(f'Epoch {epoch + 1}, train loss: {torch.tensor(losses).mean():.2f}, train acc: {torch.tensor(accuracies).mean():.2f}')\n",
    "\n",
    "    losses = list()\n",
    "    accuracies = list()\n",
    "    for batch in val_loader:\n",
    "        x, y = batch\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        with torch.no_grad():\n",
    "            l = model(x)\n",
    "        J = loss(l, y.cuda())\n",
    "        \n",
    "        losses.append(J.item())\n",
    "        accuracies.append(y.eq(l.detach().argmax(dim=1)).float().mean())\n",
    "    print(f'Epoch {epoch + 1}, val loss: {torch.tensor(losses).mean():.2f}, val acc: {torch.tensor(accuracies).mean():.2f}')\n",
    "    "
   ]
  },
  {
   "source": [
    "<h2>Save and Load</h2>\n",
    "This is where the model is exported as a dictionary and then imported back to the script to ensure the model is saved."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: SAVE AND LOAD MODEL HERE; export as dict and load dict into nn module\n",
    "PATH = './cifar_model.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "trained_model = \"Load model into this variable?\""
   ]
  },
  {
   "source": [
    "<h2>Load Test Data</h2>\n",
    "Similar to the validation training, the test data, unseen data by the model, is loaded to test the correctness of the trained network."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size = len(test_dataset), shuffle=True)"
   ]
  },
  {
   "source": [
    "<h2>Model Testing</h2>\n",
    "This is where the test_loader is tested upon the trained model and output the accuracy of the model on 'real data' or data that it has not seen before how well was the generalisation of the training."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the network on the 10000 test images: 77 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        x, y = data\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        outputs = model(x)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y.cuda()).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd007efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}