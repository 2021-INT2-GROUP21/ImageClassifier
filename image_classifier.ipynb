{
 "cells": [
  {
   "source": [
    "<h1>Image Classifier</h1>\n",
    "Module Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split"
   ],
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 84,
   "outputs": []
  },
  {
   "source": [
    "<h2>Cuda Test</h2>\n",
    "Code line used to set device to cuda if available"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "source": [
    "<h2>Neural Network Model Class</h2>\n",
    "The class that defines the neural network.\n",
    "Methods include the convolution layer made up of three blocks, each representing a layer in the network and params representing the number of nodes.\n",
    "Conv_layer is used to filter the data and learn from it.\n",
    "FC_layer is the feature configuration layer taking the filtered data to apply and recognise features.\n",
    "Forward is the method to move a data, x, through the network to reach an output from input."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flexible model\n",
    "#TODO: this is a copied model of the internet, we should probably look at the theory of it and try to build our own. As pointed below, build a model that can use MSE loss.\n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(p=0.05),\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten images into vectors\n",
    "         # conv layers\n",
    "        x = self.conv_layer(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CIFAR10Model().to(device)"
   ]
  },
  {
   "source": [
    "<h2>Optimiser and Loss Functions</h2>\n",
    "Using the inbuilt functionality from pytorch to create the loss and optimiser functions to train the neural network."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimiser, Stochastic Gradient Descent\n",
    "params = model.parameters()\n",
    "optimiser = optim.SGD(params, lr=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss\n",
    "#TODO: I would prefer to use MSEloss instead of CEloss thus change the model to cater to a MSEloss training. Also if you want to use MSE loss, batch_size must equal model output size, 10.\n",
    "#loss = nn.MSELoss()\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "source": [
    "<h2>Load training and validation data</h2>\n",
    "The CIFAR10 dataset is loaded here and transformed into tensors, whereby the 32x32 pixel images are transformed into multidimensional arrays and normalised so that it may be passed as input data to train the neural network. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "#train, val, label\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_data = datasets.CIFAR10(root='./.data', train=True, download=True, transform=transform)\n",
    "\n",
    "val_size = 5000\n",
    "batch_size = 16\n",
    "train, val = random_split(train_data, [len(train_data)-val_size, val_size])\n",
    "train_loader = DataLoader(train, batch_size=batch_size, num_workers=2)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, num_workers=2)\n",
    "\n",
    "# mapping from label to english description, la\n",
    "classes = train_data.classes\n",
    "classes"
   ]
  },
  {
   "source": [
    "<h2>Training</h2>\n",
    "This is where the model is trained. Epoch is the number of iterations the model trains for and outputs the loss value, how far the model was from the correct class, and accuracy of how many correct guesses it classified the images.\n",
    "Training is split into two where the train_loader is used to adjust the network via gradient descent implemented by pyTorch, val_loader is used to test the model to ensure it is not overfitting to the training data where it runs the model without changing the network."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, train loss: 1.46, train acc: 0.46\n",
      "Epoch 1, val loss: 1.08, val acc: 0.61\n",
      "Epoch 2, train loss: 0.91, train acc: 0.68\n",
      "Epoch 2, val loss: 0.79, val acc: 0.72\n",
      "Epoch 3, train loss: 0.70, train acc: 0.76\n",
      "Epoch 3, val loss: 0.73, val acc: 0.75\n",
      "Epoch 4, train loss: 0.56, train acc: 0.81\n",
      "Epoch 4, val loss: 0.66, val acc: 0.78\n",
      "Epoch 5, train loss: 0.44, train acc: 0.85\n",
      "Epoch 5, val loss: 0.67, val acc: 0.78\n",
      "Epoch 6, train loss: 0.35, train acc: 0.88\n",
      "Epoch 6, val loss: 0.71, val acc: 0.78\n",
      "Training complete in 6 iteration with training accuracy of 78.10%\n"
     ]
    }
   ],
   "source": [
    "#training and validation loop\n",
    "\n",
    "num_epochs = 8\n",
    "last_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    losses = list()\n",
    "    accuracies = list()\n",
    "    for batch in train_loader:\n",
    "        x, y = batch[0].to(device), batch[1].to(device)\n",
    "        out = model(x)\n",
    "        ce_loss = loss(out, y)\n",
    "        model.zero_grad()\n",
    "        ce_loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        losses.append(ce_loss.item())\n",
    "        accuracies.append(y.eq(out.detach().argmax(dim=1)).float().mean())\n",
    "    print(f'Epoch {epoch + 1}, train loss: {torch.tensor(losses).mean():.2f}, train acc: {torch.tensor(accuracies).mean():.2f}')\n",
    "\n",
    "    losses = list()\n",
    "    accuracies = list()\n",
    "    for batch in val_loader:\n",
    "        x, y = batch[0].to(device), batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(x)\n",
    "        ce_loss = loss(out, y)\n",
    "        \n",
    "        losses.append(ce_loss.item())\n",
    "        accuracies.append(y.eq(out.detach().argmax(dim=1)).float().mean())\n",
    "    current_val_acc = torch.tensor(accuracies).mean()\n",
    "    print(f'Epoch {epoch + 1}, val loss: {torch.tensor(losses).mean():.2f}, val acc: {current_val_acc:.2f}')\n",
    "\n",
    "    if current_val_acc <= last_val_acc:\n",
    "        break\n",
    "    else:\n",
    "        last_val_acc = current_val_acc\n",
    "print(f'Training complete in {epoch + 1} iteration with training accuracy of {100*last_val_acc:.2f}%')"
   ]
  },
  {
   "source": [
    "<h2>Save and Load</h2>\n",
    "This is where the model is exported as a dictionary and then imported back to the script to ensure the model is saved."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CIFAR10Model(\n",
       "  (conv_layer): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Dropout2d(p=0.05, inplace=False)\n",
       "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Dropout(p=0.1, inplace=False)\n",
       "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "PATH = './cifar_model.pth'\n",
    "torch.save(model, PATH)\n",
    "\n",
    "trained_model = torch.load(PATH)\n",
    "trained_model.eval()"
   ]
  },
  {
   "source": [
    "<h2>Load Test Data</h2>\n",
    "Similar to the validation training, the test data, unseen data by the model, is loaded to test the correctness of the trained network."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_dataset = datasets.CIFAR10(root='./.data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "source": [
    "<h2>Model Testing</h2>\n",
    "This is where the test_loader is tested upon the trained model and output the accuracy of the model on 'real data' or data that it has not seen before how well was the generalisation of the training."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of airplane : 73 %\nAccuracy of automobile : 73 %\nAccuracy of  bird : 75 %\nAccuracy of   cat : 73 %\nAccuracy of  deer : 82 %\nAccuracy of   dog : 70 %\nAccuracy of  frog : 85 %\nAccuracy of horse : 81 %\nAccuracy of  ship : 93 %\nAccuracy of truck : 90 %\n\nAccuracy of total : 80 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = trained_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "print('\\nAccuracy of %5s : %2d %%' % (\n",
    "        \"total\", 100 * sum(class_correct) / sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd007efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}